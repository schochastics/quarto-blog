{
  "hash": "7b6b18e0662e3d7853df90a6e2b19d1c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"A practical benchmark of duckplyr\"\nauthor:\n- name: David Schoch\n  orcid: 0000-0003-2952-4812\ndate: '2025-03-10'\ncategories:\n- R\n- data analysis\n---\n\n\n\nBenchmarking is hard and it is really tricky to find the right type of data and settings to make a truly fair comparison of different approaches to achieve the same thing. I have seen enough heated discussions on social media. I am still curious how the shiny new version of [duckplyr](https://github.com/tidyverse/duckplyr) compares to other established data wrangling libraries in R. However, I will not attempt to do any rigorous performance analysis. This post is only driven by a practical interest of mine: I need fast summarization and fast joins. So the results may not paint the full picture.\n\n## Libraries\n\nI will just do a lazy introduction of all packages and simply paste short paragraphs from GitHub. If you are new to a package, please checkout the respective repository for more help.\n\n### dplyr  \n[dplyr](https://dplyr.tidyverse.org/) is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges\n\n### duckplyr\nThe [duckplyr](https://duckplyr.tidyverse.org/) package will run all of your existing dplyr code with identical results, using [DuckDB](https://duckdb.org/) where possible to compute the results faster. In addition, you can analyze larger-than-memory datasets straight from files on your disk or from the web.\n\n### data.table\n[data.table](https://github.com/Rdatatable/data.table) provides a high-performance version of base R's data.frame with syntax and feature enhancements for ease of use, convenience and programming speed.\n\n### polars\nThe [polars](https://github.com/pola-rs/r-polars) package for R gives users access to a lightning fast Data Frame library written in [Rust](https://www.pola.rs/).\n\n### tidypolars\n[tidypolars](https://github.com/etiennebacher/tidypolars/) provides a polars backend for the tidyverse. The aim of tidypolars is to enable users to keep their existing tidyverse code while using polars in the background to benefit from large performance gains. \n\n### collapse\n[collapse](https://github.com/SebKrantz/collapse) is a large C/C++-based package for data transformation and statistical computing in R. It aims to:\n\n- Facilitate complex data transformation, exploration and computing tasks in R.\n- Help make R code fast, flexible, parsimonious and programmer friendly.\n\n### Personal thoughts\n\nI find the concepts of `duckplyr` and `tidypolars` truly amazing. You essentially get performance upgrades for free when you have been working with `dplyr`. So there is (almost) no refactoring needed. \n\n`data.table` was my first shift away from the tidyverse around 5 years ago. My football side project had grown to a size that made working with `dplyr` slightly annoying because certain operations just took to long. I did a major refactoring of the code base and since then, the project runs on `data.table`. Working with its syntax though can be a challenge and might not be intuitive for everybody (I too have to look up syntax all the time) \n\nI do like Rust and I have been experimenting with it a lot, mostly to get it to work with [R](https://blog.schochastics.net/#category=Rust). So it may come as no surprise that I do like `polars`. Similar to `data.table`, its syntax might not be as straightforward, but thats what we now have `tidypolars` for. \n\nWhile I never really used `collapse`, I do have mad respect for its main developer, Sebastian Krantz. I'd encourage you to read his blog posts on [collapse 2.0](https://sebkrantz.github.io/Rblog/2023/10/17/releasing-collapse-2-0-blazing-fast-joins-reshaping-and-enhanced-r/) and on \n[the state of the fastverse](https://sebkrantz.github.io/Rblog/2023/04/12/collapse-and-the-fastverse-reflecting-the-past-present-and-future/).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(duckplyr)\nlibrary(data.table)\nlibrary(polars)\nlibrary(tidypolars)\nlibrary(collapse)\n\npackageVersion(\"dplyr\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '1.1.4'\n```\n\n\n:::\n\n```{.r .cell-code}\npackageVersion(\"duckplyr\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '1.0.1'\n```\n\n\n:::\n\n```{.r .cell-code}\npackageVersion(\"data.table\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '1.16.4'\n```\n\n\n:::\n\n```{.r .cell-code}\npackageVersion(\"polars\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '0.22.1'\n```\n\n\n:::\n\n```{.r .cell-code}\npackageVersion(\"tidypolars\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '0.13.0'\n```\n\n\n:::\n\n```{.r .cell-code}\npackageVersion(\"collapse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '2.1.0'\n```\n\n\n:::\n:::\n\n\n\n## Data\n\nThe data I am using is a set of ~1 million football game results around the world. You can find the data on [GitHub](https://github.com/schochastics/football-data) (This data set is part of my [worldclubratings](http://worldclubratings.net) side project.).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- nanoparquet::read_parquet(\"games.parquet\")\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'tbl' and 'data.frame':\t1237935 obs. of  17 variables:\n $ home          : chr  \"Bolton Wanderers\" \"Everton FC\" \"Preston North End\" \"Stoke City\" ...\n $ away          : chr  \"Derby County\" \"Accrington FC\" \"Burnley FC\" \"West Bromwich Albion\" ...\n $ date          : Date, format: \"1888-09-08\" \"1888-09-08\" ...\n $ gh            : int  3 2 5 0 1 5 5 3 1 2 ...\n $ ga            : int  6 1 2 2 1 1 5 4 2 1 ...\n $ full_time     : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ competition   : chr  \"england\" \"england\" \"england\" \"england\" ...\n $ home_ident    : chr  \"Bolton Wanderers (England)\" \"Everton FC (England)\" \"Preston North End (England)\" \"Stoke City (England)\" ...\n $ away_ident    : chr  \"Derby County (England)\" \"Accrington FC (England)\" \"Burnley FC (England)\" \"West Bromwich Albion (England)\" ...\n $ home_country  : chr  \"england\" \"england\" \"england\" \"england\" ...\n $ away_country  : chr  \"england\" \"england\" \"england\" \"england\" ...\n $ home_code     : chr  \"ENG\" \"ENG\" \"ENG\" \"ENG\" ...\n $ away_code     : chr  \"ENG\" \"ENG\" \"ENG\" \"ENG\" ...\n $ home_continent: chr  \"Europe\" \"Europe\" \"Europe\" \"Europe\" ...\n $ away_continent: chr  \"Europe\" \"Europe\" \"Europe\" \"Europe\" ...\n $ continent     : chr  \"Europe\" \"Europe\" \"Europe\" \"Europe\" ...\n $ level         : chr  \"national\" \"national\" \"national\" \"national\" ...\n```\n\n\n:::\n:::\n\n\n\nI am not going to measure the time it takes to convert the data to the needed format of the packages but just do it beforehand\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tbl <- data\ndata_duck <- as_duckdb_tibble(data)\ndata_dt <- as.data.table(data)\ndata_pl <- as_polars_df(data)\n```\n:::\n\n\n\n## Summarise\n\nThe summarise task is pretty simple: Calculate the average number of goals scored at home for each team.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- microbenchmark::microbenchmark(\n  times = 100,\n  dplyr = data_tbl |> summarise(mgh = mean(gh), .by = home),\n  duckdb = data_duck |> summarise(mgh = mean(gh), .by = home),\n  tidypolars = data_pl |> summarise(mgh = mean(gh), .by = home),\n  data.table = data_dt[, .(mgh = mean(gh)), by = .(home)],\n  rpolars = data_pl$group_by(\"home\")$agg(\n    pl$col(\"gh\")$mean()$alias(\"mgh\")\n  ),\n  collapse = data_tbl |> fgroup_by(home) |> fsummarise(mgh = mean(gh))\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in microbenchmark::microbenchmark(times = 100, dplyr =\nsummarise(data_tbl, : less accurate nanosecond times to avoid potential integer\noverflows\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot2::autoplot(res, order = \"median\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/bench-summarise-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|expr       |       min|        lq|      mean|    median|        uq|       max| neval|\n|:----------|---------:|---------:|---------:|---------:|---------:|---------:|-----:|\n|duckdb     |   501.717|   893.718|  1072.153|   983.836|  1042.282|   6323.43|   100|\n|data.table |  7990.982|  8679.249|  9921.472|  8951.366| 10053.118|  23399.23|   100|\n|rpolars    |  8781.093| 10069.354| 11119.166| 10442.290| 11024.183|  29293.72|   100|\n|collapse   | 18629.990| 20007.242| 23752.123| 21459.831| 24064.109|  97259.87|   100|\n|tidypolars | 25404.420| 27933.074| 31785.160| 30290.513| 32454.391|  78651.78|   100|\n|dplyr      | 41637.550| 47865.880| 52259.693| 49239.791| 51158.816| 131310.58|   100|\n\n\n:::\n:::\n\n\n\nIt is quite impressive how `duckplyr` is an order of magnitude faster than every other library. `data.table` and `rpolars` are the next fastest. Notably, there seems to be some overhead for the `tidypolars` package which loses some of the speed of `rpolars`. On has to note here though that both polars based packages are still under heavy development.\n\n## Join\n\nThe task for the join test os also quite straightforward. Calculate the average number of goals at home and away per team and join the resulting tables. For this task, we need to create individual join functions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njoin_dplyr <- function(df) {\n  home <- df |>\n    summarise(mgh = mean(gh), .by = home) |>\n    rename(team = home)\n  away <- df |>\n    summarise(mga = mean(ga), .by = away) |>\n    rename(team = away)\n  full_join(home, away, by = \"team\")\n}\n\njoin_duck <- join_tpl <- join_dplyr\n\njoin_dt <- function(df) {\n  home <- df[, .(mgh = mean(gh)), by = .(home)]\n  away <- df[, .(mga = mean(ga)), by = .(away)]\n  setnames(home, \"home\", \"team\")\n  setnames(away, \"away\", \"team\")\n  setkey(home, team)\n  setkey(away, team)\n  home[away, on = .(team), all = TRUE]\n}\n\njoin_pl <- function(df) {\n  home <- data_pl$group_by(\"home\")$agg(pl$col(\"gh\")$mean()$alias(\"mgh\"))\n  away <- data_pl$group_by(\"away\")$agg(pl$col(\"ga\")$mean()$alias(\"mga\"))\n  home <- home$rename(\"home\" = \"team\")\n  away <- away$rename(\"away\" = \"team\")\n  home$join(away, on = \"team\", how = \"full\")\n}\n\njoin_collapse <- function(df) {\n  home <- df |>\n    fgroup_by(home) |>\n    fsummarise(mgh = mean(gh)) |>\n    frename(team = home)\n  away <- df |>\n    fgroup_by(away) |>\n    fsummarise(mga = mean(ga)) |>\n    frename(team = away)\n  join(home, away, on = \"team\", how = \"full\", verbose = 0)\n}\n```\n:::\n\n\n\nHere you see the advantage of `tidypolars` and `duckplyr`. Both can simply reuse the `dplyr` function and the packages do the magic in the background.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- microbenchmark::microbenchmark(\n  times = 100,\n  dplyr = join_dplyr(data_tbl),\n  duckplyr = join_dplyr(data_duck),\n  tidypolars = join_tpl(data_pl),\n  data.table = join_dt(data_dt),\n  rpolars = join_pl(data_pl),\n  collapse = join_collapse(data_tbl)\n)\n\nggplot2::autoplot(res, order = \"median\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|expr       |       min|        lq|       mean|     median|         uq|       max| neval|\n|:----------|---------:|---------:|----------:|----------:|----------:|---------:|-----:|\n|duckplyr   |   3.65802|   4.59036|   5.761749|   4.859259|   5.380369|  35.79066|   100|\n|rpolars    |  21.48490|  22.79342|  24.203079|  23.763620|  24.662996|  36.97105|   100|\n|data.table |  21.76813|  23.00215|  26.245189|  23.848450|  25.703761| 114.19017|   100|\n|collapse   |  37.69208|  40.77114|  45.115248|  43.676398|  46.194065| 140.04198|   100|\n|tidypolars |  56.60940|  60.21408|  62.954750|  62.261903|  65.112818|  75.73905|   100|\n|dplyr      | 134.39898| 140.52020| 147.755016| 144.589472| 149.807604| 247.84689|   100|\n\n\n:::\n:::\n\n\n\nThe results remain pretty much the same as before. `duckplyr` is much faster than the remaining libraries, with `rpolars` and `data.table` on a similar level as the second best options.\n\n## Summary\n\nAs I said in the beginning, this was not a very comprehensive benchmark, but tailored to my personal use case scenarios. I would be really interested in more rigorous benchmarks but till then, I will happily switch to `duckplyr` for my backend.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}