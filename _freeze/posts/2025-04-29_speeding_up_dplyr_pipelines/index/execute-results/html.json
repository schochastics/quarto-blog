{
  "hash": "f6ab6d7f652c8c59f13da599f87e8c2e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Profiling dplyr pipelines\"\nauthor:\n- name: David Schoch\n  orcid: 0000-0003-2952-4812\ndate: '2025-04-29'\ncategories:\n- R\n- data analysis\n---\n\n\n\n\nRecently I had to deal with refactoring some legacy R code. The code consisted of many long dplyr pipelines which were\ncalled over and over in an iterative process. The refactoring constraints were to not change the paradigm (so don't reimplement with, say, `data.table`)\nand keep the complexity low to ensure long term maintainability. While improving performance was not a primary concern, these constraints did pose an interesting challenge to see how much more efficient existing code can get without switching to a different framework and keeping the code readable.  \n\nIn this blog post, I will talk about some odf the performance improving steps that I implemented. If you  are interested in profiling R code more generally, I recommend the chapter on that topic Hadley's book [Advanced R](http://adv-r.had.co.nz/Profiling.html). Nevertheless, I would like to start with some basics about profiling before jumping into the coding part.\n\n## What is Profiling?\n\nProfiling is the process of analyzing a program to measure aspects of its performance, particularly time and memory usage.\nProfiling helps to understand where code spends most of its computational resources, which functions are called most frequently, and where potential bottlenecks exist. The goal is not simply to “make things faster” but to identify the most significant contributors to inefficiency so that optimization efforts are focused and effective.\n\n## When is Profiling Useful?\n\nProfiling is particularly useful when:\n\n- **Performance is a concern**: When the code takes longer to execute than acceptable, especially in production systems.\n- **Resource limitations exist**: When high memory usage leads to crashes or excessive consumption of server resources.\n- **Optimizing for scalability**: When preparing code that needs to handle larger datasets or concurrent workloads.\n- **Prioritizing optimization**: Before refactoring or optimizing code, profiling ensures that effort is invested in the parts of the code that will yield the biggest improvements.\n\nImportantly, premature optimization — trying to speed up code without first profiling — often leads to wasted effort or even slower and more complex code.\n\n## When to stop Profiling\n\nYou will obviously not be able to improve the performance of your code infinitely many times. You will eventually reach a point, where you find yourself spending more time improving performance than your code will run. In other words: Is it worth spending 4 hours to squeeze out 5 more seconds of runtime?\nAn important part of profiling and improving code is to recognize when to stop. There are some basic rules you follow. \n\n> The performance is acceptable for the operational needs\n\nIf it is acceptable that your code needs 5 minutes to run, then why bother making it work in 4:30? If you feel like it is worth doing, think about the following.\n\n> The remaining inefficiencies are minor and not worth the extra complexity optimization would introduce \n\nThis follows the 80/20 rule — 80% of the performance gain often comes from optimizing 20% of the code. This rule is particularly \nimportant when you write code for a client. You may pet your own shoulder about squeezing out that extra 30 seconds but the code needed is so complex, that\nthe client will not be able to maintain the code for long. Even you may not understand your clever idea after a month (or even a week) anymore.\nTo make it an explicit rule:\n\n> Further optimization compromises readability, maintainability, or correctness.\n\nBasically what I said before: Optimization always has a trade-off with code simplicity. Highly optimized code can become harder to understand and maintain, so balance is crucial.\n\n## Important (Best) Practices\n\nEffective profiling and optimization require a thoughtful approach. Below are some practices to ensure that your profiling activities are efficient and beneficial for long-term maintenance.\n\nFirst and foremost, it is important to **profile both before and after any changes**. Running a profiler on the original code provides a baseline measurement of the performance. This allows you to identify where the actual bottlenecks are, rather than relying on assumptions. After making changes, re-running the profiler will help to confirm that the changes had the intended effect. \n\nIn a data scientific context, this might not be the highest priority but in general, it is important to **prioritize algorithmic efficiency over minor code tweaks**. In other words, improving the underlying approach or algorithm typically yields far greater performance gains than micro-optimizations such as changing how loops are written or tweaking minor operations. Replacing a quadratic time algorithm with a linear time one will have a dramatic impact, while optimizing individual function calls within a poor algorithm will have limited effect.\n\nAnother important practice (and one that I consistently fail to adhere to) is to **document profiling findings and optimization steps**. Each bottleneck identified, each change made, and each observed performance improvement should be recorded somewhere. This documentation ensures that future maintainers of the code understand why certain optimizations were made and prevents “optimization amnesia” — the phenomenon where performance-degrading changes are accidentally reintroduced because the reasons for the original optimization were forgotten.\n\nAdditionally, it is essential to **avoid premature optimization**. Many parts of a system may be sufficiently fast already, and trying to optimize them can waste time, introduce bugs, and make code harder to read and maintain. You should resist the temptation to “make everything faster” and instead focus their efforts only on areas where performance is demonstrably inadequate. Always follow the stoping rules above and Donald Knuth: “Premature optimization is the root of all evil”.\n\n## Profiling dplyr pipelines\n\nWith the theory out of the way, I want to show some small code improvements that had a large impact on the performance of the legacy code I was working with.\nRecall the setting: A series of dplyr pipelines that are called over and over in an iterative process (~50000 times). The thing to keep in mind here is that if a piece of code runs in around 0.5 second, which is more than acceptable if you run the code once, it takes 6 hours to run it 50000 times! If we can cut this to 0.05 seconds, we would already be at under an hour total runtime!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n:::\n\n\n\n\n### Replace `if_else` for binary variables\n\nI tend to overuse `if_else` and so did the legacy code. The function is not bad in general, but in many instances, it can be replaced with a \nmore efficient computation. In my case, the `if_else` was replacing a value with zero depending on the status of a binary variable.\n\nThis is what the data looked like.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nentities <- paste0(\"V\", 1:300)\nn <- 1e5\ndat <- tibble(\n  name = sample(entities, n, replace = TRUE),\n  binary = sample(c(0L, 1L), n, replace = TRUE, prob = c(0.8, 0.2)),\n  value = round(runif(n, 100, 1000), 2)\n)\n```\n:::\n\n\n\n\nThe task is to sum up the `value` column grouped by `name` but replacing `value` by zero depending on the value of `binary`. Below is the `if_else` solution.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbinary_ifelse <- function(dat) {\n  dat |>\n    group_by(name) |>\n    summarise(\n      value_1 = sum(\n        if_else(binary == 1, value, 0),\n        na.rm = TRUE\n      ),\n      value_0 = sum(\n        if_else(binary == 0, value, 0),\n        na.rm = TRUE\n      )\n    )\n}\n```\n:::\n\n\n\n\nThis can be quite neatly replaced with a simple arithmetic computation which completely circumvents the use of `if_else()`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbinary_arithmetic <- function(dat) {\n  dat |>\n    group_by(name) |>\n    summarise(\n      value_1 = sum(binary * value, na.rm = TRUE),\n      value_0 = sum(\n        (1 - binary) * value,\n        na.rm = TRUE\n      )\n    )\n}\n```\n:::\n\n\n\n\nLet's benchmark this.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbench::mark(\n  binary_ifelse(dat),\n  binary_arithmetic(dat)\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  expression                  min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>             <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 binary_ifelse(dat)       29.7ms  30.58ms      31.9   15.85MB     37.9\n2 binary_arithmetic(dat)   2.52ms   2.72ms     322.     4.95MB     49.9\n```\n\n\n:::\n:::\n\n\n\n\nThe arithmetic code is roughly 15 times faster. \nAnother `if_else` use case I have seen is to replace `NA` values. Here we can use dedicated functions such as `tidyr::replace_na` instead.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$valueNA <- dat$value\ndat$valueNA[sample(1:n, floor(n / 50))] <- NA\nif_else_NA <- function(dat) {\n  dat |>\n    mutate(valueNA = if_else(is.na(valueNA), 0, valueNA))\n}\n\nreplace_NA <- function(dat) {\n  dat |> mutate(valueNA = tidyr::replace_na(valueNA, 0))\n}\n\nbench::mark(\n  if_else_NA(dat),\n  replace_NA(dat)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  expression           min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>      <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 if_else_NA(dat)   1.05ms    1.2ms      821.     4.8MB    154. \n2 replace_NA(dat) 312.01µs  354.8µs     2808.    1.98MB     89.5\n```\n\n\n:::\n:::\n\n\n\n\nThis is not too much of a performance gain, but arguably is more readable.\n\n### Precompute values\n\nSo this one is not directly connected to `dplyr` pipelines but a more general advice for iterative processes. If at all possible, precompute values or create lookup dictionaries instead of reevaluate them within the iterations. My use case was a large data frame where in each iteration, a filter was run to obtain the relevant data points for the iteration step. This can actually be done beforehand by splitting the data frame, so that during the iteration, we just need to look up the relevant values.\nThis is practically always more efficient than recomputing values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 1e6\ndat <- tibble(\n  iter = sample(1:10000, size = n, replace = TRUE),\n  data = runif(n)\n)\n\nbench::mark(\n  filter = for (i in 1:10000) dat |> dplyr::filter(iter == i),\n  split = {\n    lst = split(dat, dat$iter)\n    for (i in 1:10000) {\n      lst[[i]]\n    }\n  },\n  check = FALSE,\n  iterations = 1\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 filter        36.5s    36.5s    0.0274     149GB     21.6\n2 split       186.1ms  186.1ms    5.37      57.9MB     16.1\n```\n\n\n:::\n:::\n\n\n\n\nNow this is an absolute killer for performance. Note that the lookup is basically free. The time is mostly spend on computing the split.\n\n### `select` can be slow\n\nAlthough slow is relative here, it was a bit of a surprise to me that replacing `select` with a base R equivalent did overall improve performance by quite a lot. Here is one example that had a large impact.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 1e4\nmat <- matrix(runif(15 * n), n, 15)\ncolnames(mat) <- letters[1:15]\ndat_old <- as_tibble(mat)\n\nmat <- matrix(runif(10 * n), n, 10)\ncolnames(mat) <- letters[1:10]\n\ndat_new <- as_tibble(mat)\n\nbench::mark(\n  dat_old |> select(-k, -l, -m, -n, -o),\n  dat_old[, !names(dat_old) %in% c(\"k\", \"l\", \"m\", \"n\", \"o\")]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  expression                            min  median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>                       <bch:tm> <bch:t>     <dbl> <bch:byt>    <dbl>\n1 \"select(dat_old, -k, -l, -m, -n… 358.22µs   381µs     2588.     837KB     49.8\n2 \"dat_old[, !names(dat_old) %in%…   6.85µs   7.5µs   131228.        0B     52.5\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}