{
  "hash": "f94d01b24dcac0c2593821a2f50878d9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"R with RAGS: An Introduction to rchroma and ChromaDB\"\nauthor:\n- name: David Schoch\n  orcid: 0000-0003-2952-4812\ndate: '2025-03-26'\ncategories:\n- R\n- data analysis\n- RAGs\n---\n\n\n\nIn the fast-moving world of large language models (LLMs), tools that help ground models in real, context-aware information are rapidly growing in importance. One of the most powerful of these tools is retrieval-augmented generation (RAG) — a technique that allows LLMs to retrieve relevant documents at generation time, rather than relying solely on their internal (and often outdated) knowledge.\n\nThanks to the package [rchroma](https://github.com/cynkra/rchroma), you can now bring high-performance, vector-based retrieval also into your R workflows, backed by [ChromaDB](https://www.trychroma.com/).\n\n![](rchroma.png)\n\n## What are RAGs?\n\nIn traditional LLM usage, the model answers a question based solely on what it learned during training. This can work well — but it has serious limitations:\n- LLMs may not know recent events or updates\n- They may “hallucinate” facts when unsure\n- You can’t give them custom/private context without fine-tuning\n\nRAG can overcome these issues.\n\nA RAG pipeline works like this:\n1. A user asks a question: “How does the billing system in our API work?”\n2. The system retrieves relevant documents (e.g., markdown files, logs, internal wiki pages)\n3. The LLM is given both the question and those retrieved documents\n4. The LLM then generates an answer grounded in actual knowledge\n\nIt’s like giving the model its own mini search engine — one that only looks through your data.\n\nThe following table summarizes some of the differences\n\n| Feature              | General LLM            | RAG System                              |\n|----------------------|------------------------|------------------------------------------|\n| Source of knowledge  | Trained model weights  | Retrieved documents + model              |\n| Updates with new info| Needs re-training      | Can retrieve new docs immediately        |\n| Hallucination risk   | Higher                 | Reduced — answers grounded in context    |\n| Use with private data| Difficult              | Easy — just feed relevant docs at query time |\n\n## ChromaDB: A vector database\n\nAt the heart of every RAG pipeline is a vector database — a system that stores high-dimensional embeddings of text and lets you search by meaning, not just keywords.\n\nChromaDB is one of the most powerful and accessible vector stores out there:\nIt is fast, lightweight, and open-source. It can easily be run locally via Docker and fully supports filtering, metadata, and semantic search. It also integrates well with popular embedding models (OpenAI, Hugging Face, etc.), a key component for a RAG system.\n\nWith ChromaDB, you can store 10,000s or even millions of text chunks, and instantly find the most relevant ones for any query — all by comparing their embeddings.\n\n## Introducing rchroma\n\nrchroma is an R interface to ChromaDB with which you can connect to\na running (Docker) Chroma instance and use the API to create collections, store documents + metadata + embeddings and query by embedding to find the most relevant documents.\n\n`rchroma` has an inbuilt convenience function to start a docker container which runs chromadb. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rchroma)\nchroma_docker_run()\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\nThe functions has many arguments but the defaults are sensible and don't need to be changed under normal circumstances. The only argument worth considering changing is `volumne_host_dir` which specifies where the database should be stored.\n\nTo connect to the running Docker container, simply use `chroma_connect()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclient <- chroma_connect()\nclient\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<chromadb connection>\n```\n\n\n:::\n:::\n\n\n\nNow we are set to start adding data to a database.\n\n## Example \nIn the following example, we use wikipedia articles of philosophers to create a knowledge base for our experiment. The (folded) code below shows how to retrieve the articles.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(purrr)\nlibrary(tibble)\n\nphilosophers <- c(\n  # Classical Western\n  \"Plato\",\n  \"Aristotle\",\n  \"Socrates\",\n  \"Epicurus\",\n  \"Pythagoras\",\n  # Medieval\n  \"Augustine_of_Hippo\",\n  \"Thomas_Aquinas\",\n  \"Boethius\",\n  \"Avicenna\",\n  \"Maimonides\",\n  # Early Modern\n  \"René_Descartes\",\n  \"Baruch_Spinoza\",\n  \"John_Locke\",\n  \"David_Hume\",\n  \"Immanuel_Kant\",\n  # 19th Century\n  \"Georg_Wilhelm_Friedrich_Hegel\",\n  \"Arthur_Schopenhauer\",\n  \"Karl_Marx\",\n  \"Friedrich_Nietzsche\",\n  \"John_Stuart_Mill\",\n  # 20th Century / Contemporary\n  \"Ludwig_Wittgenstein\",\n  \"Bertrand_Russell\",\n  \"Martin_Heidegger\",\n  \"Jean-Paul_Sartre\",\n  \"Simone_de_Beauvoir\",\n  \"Michel_Foucault\",\n  \"Hannah_Arendt\",\n  \"Jacques_Derrida\",\n  \"Jürgen_Habermas\",\n  \"Richard_Rorty\",\n  # Non-Western Philosophers\n  \"Confucius\",\n  \"Laozi\",\n  \"Zhuangzi\",\n  \"Nagarjuna\",\n  \"Adi_Shankara\",\n  \"Mencius\",\n  \"Al-Farabi\",\n  \"Ibn_Rushd\",\n  \"Wang_Yangming\",\n  \"Dogen\"\n)\n\nuuid <- function() {\n  shortuuid::uuid_to_bitcoin58(shortuuid::generate_uuid())\n}\n\nget_philosopher_article_with_metadata <- function(title) {\n  url <- paste0(\"https://en.wikipedia.org/wiki/\", title)\n  page <- tryCatch(read_html(url), error = function(e) NULL)\n  if (is.null(page)) {\n    return(NULL)\n  }\n\n  # Get readable title\n  readable_title <- str_replace_all(title, \"_\", \" \")\n\n  # Extract text content (paragraphs)\n  content <- page |>\n    html_elements(\"#mw-content-text .mw-parser-output > p\") |>\n    html_text2()\n\n  content <- content[nchar(content) > 100] # Filter out short/noisy chunks\n\n  # Extract infobox rows\n  infobox_rows <- page |>\n    html_element(\".infobox\") |>\n    html_elements(\"tr\")\n\n  # Helper to extract values\n  extract_row_value <- function(label) {\n    value <- infobox_rows |>\n      keep(~ str_detect(html_text2(.x), fixed(label))) |>\n      html_elements(\"td\") |>\n      html_text2()\n    if (length(value) > 0) value[[1]] else NA\n  }\n\n  metadata <- list(\n    name = readable_title,\n    birth = extract_row_value(\"Born\"),\n    died = extract_row_value(\"Died\"),\n    region = extract_row_value(\"Region\"),\n    school_tradition = extract_row_value(\"School\"),\n    main_interests = extract_row_value(\"Main interests\"),\n    notable_ideas = extract_row_value(\"Notable ideas\")\n  )\n  Sys.sleep(runif(1, 0.5, 1))\n  print(title)\n  # Return content + metadata for each chunk\n  tibble(\n    id = map_chr(seq_along(content), ~ uuid()),\n    title = readable_title,\n    chunk = seq_along(content),\n    content = content,\n    metadata = list(metadata)\n  )\n}\n\nphilosopher_articles <- map_dfr(\n  philosophers,\n  get_philosopher_article_with_metadata\n)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\nWe also need to calculate an embedding for each of the text chunks. There are many ways of doing this.\n\nThe folded code below shows an example using `reticulate`. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nreticulate::virtualenv_create(\"rchroma_env\")\nreticulate::virtualenv_install(\n  \"rchroma_env\",\n  packages = c(\"sentence-transformers\")\n)\nreticulate::use_virtualenv(\"rchroma_env\", required = TRUE)\nsentence_transformers <- reticulate::import(\"sentence_transformers\")\nmodel <- sentence_transformers$SentenceTransformer(\"all-MiniLM-L6-v2\")\n\nembeddings <- model$encode(philosopher_articles$content)\nphilosopher_articles$embedding <- lapply(\n  seq_len(nrow(philosopher_articles)),\n  function(i) embeddings[i, ]\n)\n```\n:::\n\n\n\nIn the experiment I will use an unreleased R package prototype based on Ollama with a function `get_embedding()` that does not rely on Python.\n\nWe now assume that we have a dataset that looks a little like the following.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::glimpse(philosopher_articles)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 2,905\nColumns: 6\n$ id        <chr> \"UtQx4t2HmGVw3iZjeQCehx\", \"5x42RR9NkaNbK2QhcdqnP1\", \"WL4W87J…\n$ title     <chr> \"Plato\", \"Plato\", \"Plato\", \"Plato\", \"Plato\", \"Plato\", \"Plato…\n$ chunk     <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ content   <chr> \"Plato (/ˈpleɪtoʊ/ PLAY-toe;[1]Greek: Πλάτων, Plátōn; born c…\n$ metadata  <list> [\"Plato\", \"428/427 or 424/423 BC\\n\\nAthens\", \"348/347 BC\\n\\…\n$ embedding <list> <0.271020502, 1.358236551, -2.413264513, -2.002642870, 1.72…\n```\n\n\n:::\n:::\n\n\n\nBefore pushing this into a database, we first create a new collection.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_collection(client, \"philosophers\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$id\n[1] \"b8d45a72-f4ea-4c3f-964d-26a97ec7ea4c\"\n\n$name\n[1] \"philosophers\"\n\n$configuration_json\n$configuration_json$hnsw_configuration\n$configuration_json$hnsw_configuration$space\n[1] \"l2\"\n\n$configuration_json$hnsw_configuration$ef_construction\n[1] 100\n\n$configuration_json$hnsw_configuration$ef_search\n[1] 100\n\n$configuration_json$hnsw_configuration$num_threads\n[1] 8\n\n$configuration_json$hnsw_configuration$M\n[1] 16\n\n$configuration_json$hnsw_configuration$resize_factor\n[1] 1.2\n\n$configuration_json$hnsw_configuration$batch_size\n[1] 100\n\n$configuration_json$hnsw_configuration$sync_threshold\n[1] 1000\n\n$configuration_json$hnsw_configuration$`_type`\n[1] \"HNSWConfigurationInternal\"\n\n\n$configuration_json$`_type`\n[1] \"CollectionConfigurationInternal\"\n\n\n$metadata\nNULL\n\n$dimension\nNULL\n\n$tenant\n[1] \"default_tenant\"\n\n$database\n[1] \"default_database\"\n\n$version\n[1] 0\n\n$log_position\n[1] 0\n```\n\n\n:::\n:::\n\n\n\nNow we add all the documents to this collection, including metadata and embeddings.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_documents(\n  client,\n  collection_name = \"philosophers\",\n  documents = philosopher_articles$content,\n  ids = philosopher_articles$id,\n  metadatas = lapply(seq_len(nrow(philosopher_articles)), function(i) {\n    list(\n      title = philosopher_articles$title[i],\n      chunk = philosopher_articles$chunk[i]\n    )\n  }),\n  embeddings = philosopher_articles$embedding\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\nNow we can start asking questions. Note that we need to also embed the question.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquery_text <- \"What is the role of ethics in philosophy?\"\nquery_embedding <- get_embedding(query_text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresult <- query(\n  client,\n  collection_name = \"philosophers\",\n  query_embeddings = list(query_embedding),\n  n_results = 3\n)\n\npurrr::map(result, unlist)$documents\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Schopenhauer asserts that the task of ethics is not to prescribe moral actions that ought to be done, but to investigate moral actions. As such, he states that philosophy is always theoretical: its task to explain what is given.[58]\"                                                                                                                                                                     \n[2] \"What is relevant for ethics are individuals who can act against their own self-interest. If we take a man who suffers when he sees his fellow men living in poverty and consequently uses a significant part of his income to support their needs instead of his own pleasures, then the simplest way to describe this is that he makes less distinction between himself and others than is usually made.[60]\"\n[3] \"Aristotle considered ethics to be a practical rather than theoretical study, i.e., one aimed at becoming good and doing good rather than knowing for its own sake. He wrote several treatises on ethics, most notably including the Nicomachean Ethics.[139]\"                                                                                                                                                 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nquery_text <- \"Can we truly know anything?\"\nquery_embedding <- get_embedding(query_text)\n\nresult <- query(\n  client,\n  collection_name = \"philosophers\",\n  query_embeddings = list(query_embedding),\n  n_results = 3\n)\n\npurrr::map(result, unlist)$documents\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"The Phenomenology of Spirit shows that the search for an externally objective criterion of truth is a fool's errand. The constraints on knowledge are necessarily internal to spirit itself. Yet, although theories and self-conceptions may always be reevaluated, renegotiated, and revised, this is not a merely imaginative exercise. Claims to knowledge must always prove their own adequacy in real historical experience.[99]\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[2] \"Thomas Aquinas believed \\\"that for the knowledge of any truth whatsoever man needs divine help, that the intellect may be moved by God to its act.\\\"[162] However, he believed that human beings have the natural capacity to know many things without special divine revelation, even though such revelation occurs from time to time, \\\"especially in regard to such (truths) as pertain to faith.\\\"[163] But this is the light that is given to man by God according to man's nature: \\\"Now every form bestowed on created things by God has power for a determined act[uality], which it can bring about in proportion to its own proper endowment; and beyond which it is powerless, except by a superadded form, as water can only heat when heated by the fire. And thus the human understanding has a form, viz. intelligible light, which of itself is sufficient for knowing certain intelligible things, viz. those we can come to know through the senses.\\\"[163]\"\n[3] \"For the advancement of science and protection of liberty of expression, Russell advocated The Will to Doubt, the recognition that all human knowledge is at most a best guess, that one should always remember:\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n```\n\n\n:::\n:::\n\n\n\n\nTo stop the docker container, simply call\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchroma_docker_stop()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ Container chromadb has been stopped.\n```\n\n\n:::\n:::\n\n\n\n## Summary\n\nSo that’s a quick dive into the world of RAGs — and how you can start building them in R using `rchroma` and ChromaDB. We looked at what RAGs actually are, how they’re different from just prompting a big language model, and why having a vector database like ChromaDB is awesome. Then we got hands-on with a little example using Wikipedia philosopher data — because what better way to test semantic search than with some ancient wisdom?\n\nWith `rchroma`, you can now start plugging in your own documents, support pages, logs, research notes — whatever you want your model to \"know.\" It’s fast, flexible, and lot's of fun to play with.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}